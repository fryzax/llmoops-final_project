import pandas as pd
import json
import matplotlib.pyplot as plt

# === 1Ô∏è‚É£ Charger ton CSV Langfuse ===
csv_path = "1761490957457-lf-traces-export-cmh270g6p000mad07qlm3ynvv.csv"
df = pd.read_csv(csv_path)

print("\n‚úÖ CSV charg√© avec succ√®s.")
print(f"{len(df)} lignes d√©tect√©es.")


# === 2Ô∏è‚É£ Parseur multi-niveaux pour la colonne 'output' ===
def parse_output(output_str):
    if not isinstance(output_str, str):
        return {}

    txt = output_str.strip()
    for i in range(4):  # on essaie plusieurs d√©codages
        try:
            txt = txt.replace('""', '"').replace('\\"', '"').strip('"')
            data = json.loads(txt)
            if isinstance(data, dict) and "metadata" in data:
                return data["metadata"]
            if isinstance(data, str):
                txt = data
                continue
        except Exception:
            continue
    return {}

# Application du parseur
df["parsed_metadata"] = df["output"].apply(parse_output)

# V√©rif : affichage d‚Äôun exemple
print("\nExemple de metadata extraite :")
example = df["parsed_metadata"].iloc[0]
print(example if example else "‚ö†Ô∏è Vide ‚Äî JSON non encore d√©cod√©.")


# === 3Ô∏è‚É£ Normaliser les metadata ===
meta_df = pd.json_normalize(df["parsed_metadata"])
meta_df.columns = [c.replace("metadata.", "") for c in meta_df.columns]
final_df = pd.concat([df, meta_df], axis=1)

print("\nColonnes d√©tect√©es dans le DataFrame final :")
print(final_df.columns.tolist())

# === 4Ô∏è‚É£ D√©tection dynamique ===
num_cols = [c for c in final_df.columns if any(x in c for x in [
    "latency_seconds", "input_tokens", "output_tokens", "total_tokens", "article_word_count"
])]

if not num_cols:
    print("\n‚ö†Ô∏è Toujours aucune colonne num√©rique trouv√©e. V√©rifions une ligne brute :")
    print(df["output"].iloc[0][:300])  # Affiche les 300 premiers caract√®res
else:
    print(f"\n‚úÖ Colonnes num√©riques d√©tect√©es : {num_cols}")
    for c in num_cols:
        final_df[c] = pd.to_numeric(final_df[c], errors="coerce")

    print("\nüìä R√©sum√© statistique :")
    print(final_df[num_cols].describe())

    # === 5Ô∏è‚É£ Graphiques ===
    if "latency_seconds" in final_df.columns:
        plt.figure(figsize=(6,4))
        final_df["latency_seconds"].dropna().plot.hist(bins=10, edgecolor="black")
        plt.title("Distribution de la latence (secondes)")
        plt.xlabel("Latence (s)")
        plt.ylabel("Fr√©quence")
        plt.tight_layout()
        plt.show()

    if all(x in final_df.columns for x in ["article_word_count", "latency_seconds"]):
        plt.figure(figsize=(6,4))
        plt.scatter(final_df["article_word_count"], final_df["latency_seconds"])
        plt.title("Latence vs Longueur d'article")
        plt.xlabel("Nombre de mots")
        plt.ylabel("Latence (s)")
        plt.tight_layout()
        plt.show()

# === 6Ô∏è‚É£ Sauvegarde du dataset nettoy√© ===
final_df.to_csv("clean_langfuse_data.csv", index=False)
print("\nüíæ Donn√©es nettoy√©es enregistr√©es sous : clean_langfuse_data.csv")
